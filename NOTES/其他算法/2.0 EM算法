EM算法:
    介绍: EM算法也称期望最大化 (Expectation-Maximum, 简称EM).
         它是一个基础算法, 是很多机器学习领域算法的基础, 比如隐式马尔科夫算法(HMM)等等.
         EM算法是一种迭代优化策略, 由于它的计算方法中每一次迭代都分为两步
            - 第一步为期望步 (E步)
            - 第二步为极大步 (M步)
         所以算法被称为EM算法.
         它受到缺失思想影响, 最初是为了解决数据缺失情况下的参数估计问题, 其算法基础和收敛有效性等问题由Dempster, Laird和Rubin三人
         给出了详细阐述, 基本思想是:
            - 首先根据已经给出的观测数据, 估计出模型参数的值
            - 然后再根据上一步估计出的参数值估计缺失数据的 值, 再根据估计出的缺失数据加上之前已经观测到的数据重新再对参数值进行估计
            - 然后反复迭代, 直至最后收敛, 迭代结束

    极大似然估计:

    实例:

